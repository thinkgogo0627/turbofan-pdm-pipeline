import mlflow
import mlflow.pytorch
import pandas as pd
import numpy as np
import torch
from pathlib import Path
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.decomposition import PCA
from scipy.signal import savgol_filter
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression
import ast

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_DIR = Path(__file__).resolve().parents[2]
DATA_DIR = PROJECT_DIR / "data"


# [ìˆ˜ì • 1] GPU ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f" Evaluation Device: {device}")

# ==========================================
# 1. Feature Engineering Logic
# ==========================================
def apply_ema(df, sensors, alpha=0.1):
    """EMA í”¼ì²˜ ìƒì„±"""
    for sensor in sensors:
        df[f"{sensor}_ema"] = df.groupby('unit_nr')[sensor].transform(
            lambda x: x.ewm(alpha=alpha).mean()
        )
    return df

def apply_savgol(df, sensors, window=15, polyorder=2):
    """S-G Filter í”¼ì²˜ ìƒì„±"""
    safe_window = window if window % 2 == 1 else window + 1
    for sensor in sensors:
        try:
            df[f"{sensor}_sg"] = df.groupby('unit_nr')[sensor].transform(
                lambda x: savgol_filter(x, window_length=min(safe_window, len(x)) if len(x) > polyorder else len(x), 
                                      polyorder=polyorder) if len(x) > polyorder else x
            )
        except:
            df[f"{sensor}_sg"] = df[sensor]
    return df

def apply_pca(train_df, test_df, sensors):
    """PCA í”¼ì²˜ ë° Trend ìƒì„± (ì—¬ê¸°ê°€ ìˆ˜ì •ë¨!)"""
    # print("   [Logic] Applying PCA & Trend...")
    pca_scaler = StandardScaler()
    pca = PCA(n_components=1)

    # 1. PCA Calculation (Train Fit -> Test Transform)
    train_scaled = pca_scaler.fit_transform(train_df[sensors].values)
    train_pc1 = pca.fit_transform(train_scaled)
    train_df['pca_1'] = train_pc1

    test_scaled = pca_scaler.transform(test_df[sensors].values)
    test_pc1 = pca.transform(test_scaled)
    test_df['pca_1'] = test_pc1
    
    # 2. [ìˆ˜ì •ë¨] Trend Calculation (ëˆ„ë½ë˜ì—ˆë˜ ë¶€ë¶„)
    # pca_1ì˜ ë³€í™”ëŸ‰(ë¯¸ë¶„ê°’)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    for df in [train_df, test_df]:
        df['pca_1_trend'] = df.groupby('unit_nr')['pca_1'].transform(
            lambda x: x.diff().fillna(0)
        )
    
    return train_df, test_df

# ==========================================
# 2. ë°ì´í„° ì¤€ë¹„ (Dynamic Logic)
# ==========================================
def prepare_test_data_dynamic(window_size, feature_cols, min_length_limit=None):
    # min_length_limit: ì•™ìƒë¸” ì‹œ ë°ì´í„° ê°œìˆ˜ë¥¼ ë§ì¶”ê¸° ìœ„í•œ ê°•ì œ ì»¤íŠ¸ë¼ì¸
    
    IMPORTANT_SENSORS = ['sensor_2', 'sensor_3', 'sensor_4', 'sensor_7', 'sensor_11', 'sensor_12', 'sensor_15']
    col_names = ['unit_nr', 'time_cycles', 'setting_1', 'setting_2', 'setting_3'] + [f'sensor_{i}' for i in range(1, 22)]
    
    # 1. Raw Data Load
    train_df = pd.read_csv(DATA_DIR / 'raw/train_FD001.txt', sep=r'\s+', header=None, names=col_names)
    test_df = pd.read_csv(DATA_DIR / 'raw/test_FD001.txt', sep=r'\s+', header=None, names=col_names)
    
    rul_true = pd.read_csv(DATA_DIR / 'raw/RUL_FD001.txt', sep=r'\s+', header=None).values.flatten()
    MAX_RUL = 125
    rul_true = np.clip(rul_true, a_min=None, a_max=MAX_RUL)

    # 2. Logic Check & Apply
    needs_ema = any("_ema" in col for col in feature_cols)
    needs_sg = any("_sg" in col for col in feature_cols)
    needs_pca = any("pca" in col for col in feature_cols) 

    if needs_ema:
        train_df = apply_ema(train_df, IMPORTANT_SENSORS)
        test_df = apply_ema(test_df, IMPORTANT_SENSORS)
    
    if needs_sg:
        train_df = apply_savgol(train_df, IMPORTANT_SENSORS)
        test_df = apply_savgol(test_df, IMPORTANT_SENSORS)
        
    if needs_pca:
        train_df, test_df = apply_pca(train_df, test_df, IMPORTANT_SENSORS)

    # 4. Scaling
    scaler = MinMaxScaler()
    scaler.fit(train_df[feature_cols])
    test_df[feature_cols] = scaler.transform(test_df[feature_cols])

    # 5. Windowing
    X_test_list = []
    y_test_list = []

    # [ìˆ˜ì •] ì»¤íŠ¸ë¼ì¸ ì„¤ì • (ì—†ìœ¼ë©´ ìê¸° window_sizeê°€ ì»¤íŠ¸ë¼ì¸)
    threshold = min_length_limit if min_length_limit is not None else window_size

    for unit_id, group in test_df.groupby('unit_nr'):
        data = group[feature_cols].values
        
        # [í•µì‹¬ ìˆ˜ì •] ì•™ìƒë¸” ì‹±í¬ë¥¼ ë§ì¶”ê¸° ìœ„í•´ thresholdë³´ë‹¤ ì§§ìœ¼ë©´ ë¬´ì¡°ê±´ ìŠ¤í‚µ
        if len(data) < threshold: 
            continue
        
        # ë°ì´í„°ê°€ ì¶©ë¶„í•´ë„, ëª¨ë¸ ì…ë ¥ì—ëŠ” ë”± window_sizeë§Œí¼ë§Œ ì˜ë¼ì„œ ë„£ìŒ (ë’¤ì—ì„œë¶€í„°)
        X_test_list.append(data[-window_size:])
        y_test_list.append(rul_true[unit_id - 1])

    return torch.tensor(np.array(X_test_list), dtype=torch.float32), torch.tensor(np.array(y_test_list), dtype=torch.float32)


# ==========================================
# 2-1. TTA - MC Dropout
# ==========================================
def predict_with_uncertainty(model, X, n_iter=20):
    """
    MC Dropout: ì¶”ë¡  ì‹œì—ë„ Dropoutì„ ì¼œê³  ì—¬ëŸ¬ ë²ˆ ì˜ˆì¸¡ í›„ í‰ê·  ê³„ì‚°
    """
    model.train() # [ì¤‘ìš”] eval()ì´ ì•„ë‹ˆë¼ train() ëª¨ë“œë¡œ ë‘¬ì•¼ Dropoutì´ ì‘ë™í•¨!
    
    predictions = []
    with torch.no_grad():
        for _ in range(n_iter):
            # ë§¤ ë°˜ë³µë§ˆë‹¤ Dropoutì´ ë‹¤ë¥´ê²Œ í„°ì§€ë©´ì„œ ì¡°ê¸ˆì”© ë‹¤ë¥¸ ì˜ˆì¸¡ê°’ì´ ë‚˜ì˜´
            pred = model(X)
            predictions.append(pred.cpu().numpy().flatten())
            
    # (n_iter, batch_size) -> í‰ê· ë‚´ì„œ ìµœì¢… ì˜ˆì¸¡ê°’ ë„ì¶œ
    predictions = np.array(predictions)
    mean_pred = predictions.mean(axis=0)
    std_pred = predictions.std(axis=0) # ë¶ˆí™•ì‹¤ì„±(í‘œì¤€í¸ì°¨)ë„ ë¤ìœ¼ë¡œ ì–»ìŒ
    
    return mean_pred, std_pred


# ==========================================
# 3. ë©”ì¸ í‰ê°€ ì‹¤í–‰
# ==========================================
def evaluate_top_models(top_n=5):
    print(f"ğŸ” Searching for Top {top_n} models...")
    
    experiment = mlflow.get_experiment_by_name("Turbofan_RUL_Prediction")
    runs = mlflow.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=["metrics.val_rmse ASC"], # ê²€ì¦ rmse ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
        max_results=top_n
    )

    for index, run in runs.iterrows():
        run_id = run.run_id
        model_name = run['params.model_type']
        window_size = int(run['params.window_size'])
        
        try:
            feature_cols = ast.literal_eval(run['params.features'])
        except:
            from src.models.model_config import TRAINER_CONFIG
            feature_cols = TRAINER_CONFIG['features']

        print(f"\n[{index+1}/{top_n}] Evaluating {model_name} (ID: {run_id})")
        
        try:
            model = mlflow.pytorch.load_model(f"runs:/{run_id}/model")
            
            # ëª¨ë¸ì„ GPUë¡œ ì´ë™
            model.to(device)
            model.eval()
        except:
            print("   âŒ Load Failed.")
            continue

        X_test, y_true = prepare_test_data_dynamic(window_size, feature_cols)
        
        if X_test is None:
            continue
        
        # ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™ ë° Shape ë§ì¶”ê¸°
        # X_test ì›ë³¸: (Batch, Window, Feature)

        ## CNN / CNNAttention: Conv1d ì‚¬ìš© -> (Batch, Feature, Time) -> Transpose í•´ì•¼í•¨
        ## Transformer: Linear ë ˆì´ì–´ -> (Batch, Time, Feature) -> Transpose í•˜ë©´ ì•ˆë¨

        X_test = X_test.to(device)
        
        # [Shape ë§ì¶”ê¸° ë¡œì§]
        if "CNN" in model_name:
            # CNN ê³„ì—´: (Batch, Feature, Window) í˜•íƒœê°€ í•„ìš”í•¨ -> Transpose O
            X_test = X_test.transpose(1, 2)
        elif "Transformer" in model_name or "DLinear" in model_name or "CNNAttention" in model_name:
            # Transformer/DLinear: (Batch, Window, Feature) í˜•íƒœ ìœ ì§€ -> Transpose X
            pass 
        else:
            X_test = X_test.transpose(1, 2)

        # [ìˆ˜ì •] ì¼ë°˜ ì˜ˆì¸¡ ë¼ì¸(model(X_test)) ì‚­ì œí•˜ê³  ë°”ë¡œ MC Dropout ì‹¤í–‰
        print(f"   ğŸ² Applying MC Dropout (n_iter=30)...")
        y_pred_flat, uncertainty = predict_with_uncertainty(model, X_test, n_iter=30)
        
        # CPUë¡œ ê°€ì ¸ì˜¤ê¸° (predict_with_uncertainty ì•ˆì—ì„œ ì´ë¯¸ cpu().numpy() ì²˜ë¦¬ë¨)
        y_true_flat = y_true.numpy().flatten()

        test_rmse = np.sqrt(mean_squared_error(y_true_flat, y_pred_flat))
        
        print(f"   ğŸ† Test RMSE (MC Dropout): {test_rmse:.4f} (Val RMSE: {run['metrics.val_rmse']:.4f})")

        with mlflow.start_run(run_id=run_id):
            mlflow.log_metric("test_rmse_mc_dropout", test_rmse)



# ==========================================
# 4. ì•™ìƒë¸” ë©”ì¸ í‰ê°€ ì‹¤í–‰
# ==========================================
def evaluate_ensemble(search_top_n=10, ensemble_top_n=3):
    print(f"ğŸš€ [Ensemble] Scanning Top {search_top_n} models to pick Best {ensemble_top_n}...")
    
    # ì‹¤í—˜ ì„¤ì •
    mlflow.set_experiment("Turbofan_RUL_Prediction") 
    
    
    experiment = mlflow.get_experiment_by_name("Turbofan_RUL_Prediction")
    runs = mlflow.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=["metrics.val_rmse ASC"], 
        max_results=search_top_n
    )
    
    # [ë‹¨ê³„ 1] ì „ì²´ ëª¨ë¸ ì¤‘ ê°€ì¥ í° Window Size ì°¾ê¸° (Synchronization)
    max_window_size_in_pool = 0
    for index, run in runs.iterrows():
        ws = int(run['params.window_size'])
        if ws > max_window_size_in_pool:
            max_window_size_in_pool = ws
    
    print(f"   âš–ï¸  Enforcing Global Min Length: {max_window_size_in_pool} (to sync all models)")

    candidates = [] 
    y_true_flat = None # ê¸°ì¤€ ì •ë‹µì§€ (ê°€ì¥ ê¸´ ìœˆë„ìš° ê¸°ì¤€)
    
    # [ë‹¨ê³„ 2] í‰ê°€ ë£¨í”„
    for index, run in runs.iterrows():
        run_id = run.run_id
        model_name = run['params.model_type']
        window_size = int(run['params.window_size'])
        
        # ëª¨ë¸ ë¡œë“œ
        try:
            model = mlflow.pytorch.load_model(f"runs:/{run_id}/model")
            model.to(device)
        except:
            continue
            
        try:
            feature_cols = ast.literal_eval(run['params.features'])
        except:
            from src.models.model_config import TRAINER_CONFIG
            feature_cols = TRAINER_CONFIG['features']
            
        # [í•µì‹¬] min_length_limitì— max_window_size_in_poolì„ ë„£ì–´ì¤ë‹ˆë‹¤.
        # ì´ë ‡ê²Œ í•˜ë©´ Window 30ì§œë¦¬ ëª¨ë¸ë„ ê¸¸ì´ê°€ 90ì¸ ë°ì´í„°ë§Œ ê³¨ë¼ì„œ í‰ê°€í•˜ë¯€ë¡œ,
        # Window 90ì§œë¦¬ ëª¨ë¸ê³¼ í‰ê°€ ë°ì´í„°ì…‹(í–‰ ê°œìˆ˜)ì´ ë˜‘ê°™ì•„ì§‘ë‹ˆë‹¤.
        X_test, y_true = prepare_test_data_dynamic(window_size, feature_cols, min_length_limit=max_window_size_in_pool)
        
        X_test = X_test.to(device)
        
        # Shape ë§ì¶¤
        if "CNN" in model_name and "CNNAttention" not in model_name:
             X_test = X_test.transpose(1, 2)
        elif "Simple1DCNN" in model_name:
             X_test = X_test.transpose(1, 2)
        
        # MC Dropout ì˜ˆì¸¡
        y_pred, _ = predict_with_uncertainty(model, X_test, n_iter=20)
        
        # ê¸°ì¤€ ì •ë‹µì§€ ì €ì¥ (í•œ ë²ˆë§Œ)
        if y_true_flat is None:
            y_true_flat = y_true.numpy().flatten()
            print(f"   âœ… Test Set Size Synced: {len(y_true_flat)} samples")
            
        # ê°œë³„ ì„±ëŠ¥ ì¸¡ì •
        individual_rmse = np.sqrt(mean_squared_error(y_true_flat, y_pred))
        print(f"  Candidate {index+1} ({model_name} / W={window_size}): RMSE {individual_rmse:.4f}")
        
        candidates.append((individual_rmse, y_pred, model_name))

    # [ë‹¨ê³„ 3] ìƒìœ„ Nê°œ ì„ ì • ë° ì•™ìƒë¸”
    candidates.sort(key=lambda x: x[0])
    top_candidates = candidates[:ensemble_top_n]
    
    print(f"\nâœ¨ Selected Top {ensemble_top_n} Models for Ensemble:")
    selected_preds = []
    for rmse, pred, name in top_candidates:
        print(f"  -> {name} (RMSE: {rmse:.4f})")
        selected_preds.append(pred)
        
    final_pred = np.mean(selected_preds, axis=0)
    final_rmse = np.sqrt(mean_squared_error(y_true_flat, final_pred))
    
    print(f"\nğŸ† Final Optimized Ensemble RMSE: {final_rmse:.4f}")

    # [ì´ ë¶€ë¶„ì´ ì‹¤í–‰ë˜ì–´ì•¼ MLflowì— ë‚¨ìŠµë‹ˆë‹¤!]
    with mlflow.start_run(run_name="Ensemble_Final_Top3"):
        mlflow.log_metric("test_rmse", final_rmse)
        mlflow.log_param("method", "Ensemble + MC Dropout")
        mlflow.log_param("models_count", ensemble_top_n)
        
        # ì„ íƒëœ ëª¨ë¸ ì´ë¦„ë“¤ë„ ê¸°ë¡
        selected_model_names = [item[2] for item in top_candidates]
        mlflow.log_param("selected_models", str(selected_model_names))
        
        print("ğŸ“ Logged Final Score to MLflow UI successfully.") # ì´ ë©”ì‹œì§€ê°€ ë– ì•¼ ì„±ê³µ!

    return final_rmse

############################################
# 5. Stacking
#############################################
from sklearn.linear_model import LinearRegression
import numpy as np
import pandas as pd
import torch
import mlflow
import ast
from numpy.lib.stride_tricks import sliding_window_view
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import MinMaxScaler

# (ê¸°ì¡´ import ë° device ì„¤ì •, prepare_test_data_dynamic ë“±ì€ ìœ„ìª½ì— ìˆë‹¤ê³  ê°€ì •)

# ----------------------------------------------------------------
# 1. Validation ë°ì´í„° ì¤€ë¹„ í•¨ìˆ˜ (Sync ê¸°ëŠ¥ í¬í•¨)
# ----------------------------------------------------------------
def prepare_val_data_synced(window_size, feature_cols, align_max_window=None):
    data_path = PROJECT_DIR / "data/processed/train_FD001_advanced_features.parquet"
    df = pd.read_parquet(data_path)
    
    # RUL Clipping
    MAX_RUL = 125
    df['RUL'] = df['RUL'].clip(upper=MAX_RUL)

    # Split
    unit_ids = df['unit_nr'].unique()
    split_idx = int(len(unit_ids) * 0.8)
    val_units = unit_ids[split_idx:]
    val_df = df[df['unit_nr'].isin(val_units)].copy()

    # Scaling
    scaler = MinMaxScaler()
    val_df[feature_cols] = scaler.fit_transform(val_df[feature_cols])

    X_list, y_list = [], []
    target_sync_len = align_max_window if align_max_window is not None else window_size

    for unit_id, group in val_df.groupby('unit_nr'):
        data = group[feature_cols].values
        target = group['RUL'].values
        
        if len(data) < target_sync_len: continue
        
        # [ìˆ˜ì •] Transpose ì œê±°! ìˆœìˆ˜í•œ (Samples, Window, Feature)ë¡œ ë°˜í™˜
        windows = sliding_window_view(data, window_shape=window_size, axis=0)
        
        target_windows = target[window_size-1:]
        
        # Sync Logic (Truncate)
        if align_max_window is not None and window_size < align_max_window:
            diff = align_max_window - window_size
            windows = windows[diff:]
            target_windows = target_windows[diff:]
            
        X_list.append(windows)
        y_list.append(target_windows)

    if not X_list: return None, None
    
    X = np.concatenate(X_list, axis=0)
    y = np.concatenate(y_list, axis=0)
    
    return torch.tensor(X, dtype=torch.float32), y

# ----------------------------------------------------------------
# 2. ìŠ¤íƒœí‚¹ ì‹¤í–‰ í•¨ìˆ˜ (ëª…í™•í•œ Transpose ë¶„ê¸°)
# ----------------------------------------------------------------
def evaluate_linear_blending(top_n=3):
    print(f"ğŸš€ [Stacking] Learning Optimal Weights from Validation Set (Top {top_n})...")
    
    mlflow.set_experiment("Turbofan_RUL_Prediction")
    experiment = mlflow.get_experiment_by_name("Turbofan_RUL_Prediction")
    runs = mlflow.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=["metrics.val_rmse ASC"], 
        max_results=top_n
    )
    
    # [ë‹¨ê³„ 1] Max Window Size ì°¾ê¸°
    max_window_in_pool = 0
    for index, run in runs.iterrows():
        ws = int(run['params.window_size'])
        if ws > max_window_in_pool: max_window_in_pool = ws
            
    print(f"   âš–ï¸  Syncing Validation Data to Window Size: {max_window_in_pool}")
    
    val_preds_matrix = [] 
    val_y_true = None
    test_preds_matrix = []
    test_y_true = None
    models_loaded = []
    
    for index, run in runs.iterrows():
        run_id = run.run_id
        model_name = run['params.model_type']
        window_size = int(run['params.window_size'])
        
        # í”¼ì²˜ íŒŒì‹± ì•ˆì „ì¥ì¹˜
        try:
            feature_cols = ast.literal_eval(run['params.features'])
        except:
            feature_cols = [
                'sensor_2', 'sensor_3', 'sensor_4', 'sensor_7', 'sensor_11', 'sensor_12', 'sensor_15',
                'pca_1', 'pca_1_trend' 
            ]

        print(f"  Load Model {index+1}: {model_name} (W={window_size})")
        
        try:
            model = mlflow.pytorch.load_model(f"runs:/{run_id}/model").to(device)
            model.eval()
        except:
            print("   âŒ Load Failed.")
            continue
            
        # -------------------------------------------------------
        # A. Validation ì˜ˆì¸¡
        # -------------------------------------------------------
        X_val, y_val = prepare_val_data_synced(window_size, feature_cols, align_max_window=max_window_in_pool)
        if X_val is None: continue
        X_val = X_val.to(device)
        
        # ğŸ”¥ [Shape Auto-Correction] ë°ì´í„° ëª¨ì–‘ì„ ë³´ê³  ê°•ì œë¡œ ë§ì¶¤ ğŸ”¥
        # í˜„ì¬ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ì°¨ì›ì´ Window Size(70)ì¸ì§€ Feature(9)ì¸ì§€ í™•ì¸
        last_dim = X_val.shape[-1]
        
        if "CNN" in model_name and "CNNAttention" not in model_name: 
            # CNNì€ (N, F, W)ì—¬ì•¼ í•¨ -> ë§ˆì§€ë§‰ì´ Window(70)ì´ì–´ì•¼ í•¨
            # ë§Œì•½ ë§ˆì§€ë§‰ì´ Feature(9)ë¼ë©´ -> ë’¤ì§‘ì–´ë¼
            if last_dim == len(feature_cols): 
                X_val = X_val.transpose(1, 2)
                
        elif "Simple1DCNN" in model_name:
             if last_dim == len(feature_cols): 
                X_val = X_val.transpose(1, 2)
                
        else:
            # Transformer/DLinear ë“±ì€ (N, W, F)ì—¬ì•¼ í•¨ -> ë§ˆì§€ë§‰ì´ Feature(9)ì—¬ì•¼ í•¨
            # ë§Œì•½ ë§ˆì§€ë§‰ì´ Window(70)ë¼ë©´ -> ë’¤ì§‘ì–´ë¼ (ì—¬ê¸°ê°€ ì—ëŸ¬ ì›ì¸ì´ì—ˆìŒ!)
            if last_dim == window_size: 
                X_val = X_val.transpose(1, 2)

        with torch.no_grad():
            p_val = model(X_val).cpu().numpy().flatten()
            
        val_preds_matrix.append(p_val)
        if val_y_true is None: val_y_true = y_val

        # -------------------------------------------------------
        # B. Test ì˜ˆì¸¡
        # -------------------------------------------------------
        X_test, y_test = prepare_test_data_dynamic(window_size, feature_cols, min_length_limit=max_window_in_pool)
        if X_test is None: continue
        X_test = X_test.to(device)
        
        # Test ë°ì´í„°ë„ ë˜‘ê°™ì´ Auto-Correction ì ìš©
        last_dim_test = X_test.shape[-1]
        
        if "CNN" in model_name and "CNNAttention" not in model_name: 
             if last_dim_test == len(feature_cols): X_test = X_test.transpose(1, 2)
        elif "Simple1DCNN" in model_name: 
             if last_dim_test == len(feature_cols): X_test = X_test.transpose(1, 2)
        else:
             # Transformer
             if last_dim_test == window_size: X_test = X_test.transpose(1, 2)

        p_test, _ = predict_with_uncertainty(model, X_test, n_iter=20)
        test_preds_matrix.append(p_test)
        
        if test_y_true is None: test_y_true = y_test.numpy().flatten()
        models_loaded.append(f"{model_name}(W={window_size})")

    # [ë‹¨ê³„ 3] Stacking
    X_meta_train = np.column_stack(val_preds_matrix)
    y_meta_train = val_y_true
    
    meta_model = LinearRegression(positive=True, fit_intercept=False)
    meta_model.fit(X_meta_train, y_meta_train)
    
    weights = meta_model.coef_
    weights = weights / np.sum(weights)
    
    print(f"\nâš–ï¸  Optimal Weights Found: {weights}")
    for name, w in zip(models_loaded, weights):
        print(f"  -> {name}: {w:.4f}")

    # [ë‹¨ê³„ 4] Inference
    X_meta_test = np.column_stack(test_preds_matrix)
    final_pred = np.dot(X_meta_test, weights)
    final_rmse = np.sqrt(mean_squared_error(test_y_true, final_pred))
    
    print(f"\nğŸ† Final Stacking RMSE: {final_rmse:.4f}")
    
    with mlflow.start_run(run_name="Stacking_Linear_Blending"):
        mlflow.log_metric("test_rmse", final_rmse)
        mlflow.log_param("weights", str(weights))
        mlflow.log_param("method", "Linear Blending Stacking")
        print("ğŸ“ Logged Stacking Score to MLflow UI successfully.")

        
if __name__ == "__main__":
    evaluate_linear_blending(top_n=3)
'''
if __name__ == "__main__":
    # Top 10ê°œë¥¼ í›‘ì–´ì„œ -> ê·¸ ì¤‘ ì œì¼ ì˜í•œ 3ê°œë§Œ ì„ì–´ë¼!
    evaluate_ensemble(search_top_n=10, ensemble_top_n=3)
    '''

'''
if __name__ == "__main__":
    evaluate_top_models(top_n=10)
    '''