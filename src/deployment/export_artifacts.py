import sys
from pathlib import Path

# 1. ê²½ë¡œ ë¨¼ì € ì„¤ì •
PROJECT_DIR = Path(__file__).resolve().parents[2]

# 2. [ê°€ì¥ ì¤‘ìš”] íŒŒì´ì¬ì´ 'src' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ê²½ë¡œë¥¼ ê°•ì œë¡œ ì£¼ì…
sys.path.append(str(PROJECT_DIR))

import os
import ast
import json
import torch
import joblib
import mlflow
import pandas as pd
from pathlib import Path
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.decomposition import PCA

# ê²½ë¡œ ì„¤ì •
PROJECT_DIR = Path(__file__).resolve().parents[2]
ARTIFACT_DIR = PROJECT_DIR / "app/artifacts"  # FastAPI ë„ì»¤ê°€ ì½ì„ í´ë”
os.makedirs(ARTIFACT_DIR, exist_ok=True)

# GPU/CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

## ê¸°ì¡´ ì•™ìƒë¸” ë¡œì§ ê·¸ëŒ€ë¡œ ì ìš©
def export_top_models(top_n=3):
    print(f"ğŸš€ [MLOps] Extracting Top {top_n} Models (by MC Dropout Test RMSE) from MLflow...")
    
    mlflow.set_experiment("Turbofan_RUL_Prediction")
    experiment = mlflow.get_experiment_by_name("Turbofan_RUL_Prediction")
    
    # [ìˆ˜ì •ëœ í•µì‹¬ ë¡œì§] 
    # Val RMSEê°€ ì•„ë‹ˆë¼, ìš°ë¦¬ê°€ ì•™ìƒë¸” ê¸°ì¤€ìœ¼ë¡œ ì‚¼ì•˜ë˜ 'test_rmse_mc_dropout' ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    # filter_stringì„ ë„£ì–´ í•´ë‹¹ ë©”íŠ¸ë¦­ì´ ì—†ëŠ”(í‰ê°€ ì•ˆ í•œ) ëª¨ë¸ì€ ì œì™¸í•©ë‹ˆë‹¤.
    runs = mlflow.search_runs(
        experiment_ids=[experiment.experiment_id],
        filter_string="metrics.test_rmse_mc_dropout > 0", 
        order_by=["metrics.test_rmse_mc_dropout ASC"], 
        max_results=top_n
    )
    
    ensemble_meta = {
        "models": [],
        "ensemble_method": "average",
        "expected_features": 9
    }
    
    # 1. ëª¨ë¸ ê°€ì¤‘ì¹˜ ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    for index, run in runs.iterrows():
        run_id = run.run_id
        model_name = run['params.model_type']
        window_size = int(run['params.window_size'])
        test_rmse_mc = run['metrics.test_rmse_mc_dropout']
        
        print(f"  -> Exporting Rank {index+1}: {model_name} (W={window_size}, MC Dropout RMSE: {test_rmse_mc:.4f})")
        
        # ëª¨ë¸ ë¡œë“œ í›„ ìˆœìˆ˜ ê°€ì¤‘ì¹˜(state_dict)ë§Œ ì¶”ì¶œ
        model = mlflow.pytorch.load_model(f"runs:/{run_id}/model").to(device)
        weight_filename = f"model_rank{index+1}_w{window_size}.pth"
        weight_path = ARTIFACT_DIR / weight_filename
        
        torch.save(model.state_dict(), weight_path)
        
        # ë©”íƒ€ë°ì´í„° ê¸°ë¡
        ensemble_meta["models"].append({
            "rank": index + 1,
            "filename": weight_filename,
            "model_type": model_name,
            "window_size": window_size,
            "test_rmse_mc_dropout": test_rmse_mc, # Val ëŒ€ì‹  Test ì ìˆ˜ë¡œ ë©”íƒ€ë°ì´í„° êµì²´
            "run_id": run_id
        })

    # ë©”íƒ€ë°ì´í„° JSON ì €ì¥
    with open(ARTIFACT_DIR / "ensemble_meta.json", "w") as f:
        json.dump(ensemble_meta, f, indent=4)
        
    print(f"âœ… Models and metadata exported to {ARTIFACT_DIR}")

def export_preprocessors():
    print(f"ğŸš€ [MLOps] Regenerating and Exporting Preprocessors (Scaler, PCA)...")
    
    # í›ˆë ¨ ë°ì´í„° ë¡œë“œ (ì •í™•íˆ í›ˆë ¨ ë•Œ ì‚¬ìš©í•œ ê·¸ ë°ì´í„°)
    train_path = PROJECT_DIR / "data/processed/train_FD001_advanced_features.parquet"
    train_df = pd.read_parquet(train_path)
    
    # ì •ì˜ˆ 9ê°œ í”¼ì²˜ (í‰ê°€ ì½”ë“œì—ì„œ ê³ ì •í–ˆë˜ ê·¸ í”¼ì²˜ë“¤)
    # pca_1, pca_1_trend ìƒì„±ì„ ìœ„í•œ ì›ë³¸ ì„¼ì„œë“¤
    raw_sensors = ['sensor_2', 'sensor_3', 'sensor_4', 'sensor_7', 'sensor_11', 'sensor_12', 'sensor_15']
    
    # 1. PCA ê°ì²´ ìƒì„± ë° ì €ì¥ (Fit)
    pca_scaler = StandardScaler()
    pca = PCA(n_components=1)
    
    train_scaled_for_pca = pca_scaler.fit_transform(train_df[raw_sensors])
    train_df['pca_1'] = pca.fit_transform(train_scaled_for_pca)
    train_df['pca_1_trend'] = train_df.groupby('unit_nr')['pca_1'].transform(lambda x: x.diff().fillna(0))
    
    joblib.dump(pca_scaler, ARTIFACT_DIR / "pca_scaler.pkl")
    joblib.dump(pca, ARTIFACT_DIR / "pca_model.pkl")
    
    # 2. MinMaxScaler ê°ì²´ ìƒì„± ë° ì €ì¥ (Fit)
    final_features = raw_sensors + ['pca_1', 'pca_1_trend']
    minmax_scaler = MinMaxScaler()
    minmax_scaler.fit(train_df[final_features])
    
    joblib.dump(minmax_scaler, ARTIFACT_DIR / "minmax_scaler.pkl")
    
    print(f"âœ… Preprocessors exported to {ARTIFACT_DIR}")

if __name__ == "__main__":
    export_top_models(top_n=3)
    export_preprocessors()
    print("ğŸ‰ All artifacts successfully packed for deployment!")