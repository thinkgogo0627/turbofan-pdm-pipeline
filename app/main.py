import time
from fastapi import FastAPI, HTTPException
from contextlib import asynccontextmanager

from app.schema import PredictRequest, PredictResponse
from app.inference import load_artifacts, predict_rul, ensemble_models

# ìµœì‹  FastAPI ë°©ì‹: ì„œë²„ ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰ë  ë¡œì§ì„ ê´€ë¦¬í•˜ëŠ” ë¼ì´í”„ì‚¬ì´í´ ë§¤ë‹ˆì €
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup: ì„œë²„ ì¼œì§ˆ ë•Œ ê°€ì¤‘ì¹˜ì™€ ì „ì²˜ë¦¬ê¸° ë©”ëª¨ë¦¬ ë¡œë“œ
    print("ğŸï¸ [Pit Wall] Starting Power Unit initialization...")
    load_artifacts()
    print("ğŸŸ¢ [Pit Wall] All systems go. Ready for telemetry data.")
    yield
    # Shutdown: ì„œë²„ êº¼ì§ˆ ë•Œ ì •ë¦¬ ë¡œì§ (í•„ìš”ì‹œ)
    print("ğŸ [Pit Wall] Shutting down Power Unit...")

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Turbofan Engine RUL Prediction API",
    description="MGU-K(Validation) + ICE(Inference) = PU(FastAPI)",
    version="1.0.0",
    lifespan=lifespan
)

@app.get("/")
def read_root():
    return {"status": "healthy", "message": "Turbofan RUL Prediction Power Unit is running."}

@app.post("/predict", response_model=PredictResponse)
def predict_engine_rul(request: PredictRequest):
    try:
        start_time = time.time()
        
        # 1. MGU-K(schemas.py)ë¥¼ í†µê³¼í•œ ë°ì´í„°ë¥¼ ICE(inference.py)ë¡œ ì „ë‹¬
        rul_value = predict_rul(request.data)
        
        end_time = time.time()
        inference_time = end_time - start_time
        print(f"â±ï¸ [Telemetry] Prediction completed in {inference_time:.4f} seconds.")

        # 2. ê²°ê³¼ë¥¼ ìŠ¤í‚¤ë§ˆì— ë§ì¶°ì„œ ë°˜í™˜
        return PredictResponse(
            predicted_rul=rul_value,
            ensemble_models_used=len(ensemble_models)
        )
    
    except Exception as e:
        print(f"âŒ [Error] Inference failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Prediction failed: {str(e)}")