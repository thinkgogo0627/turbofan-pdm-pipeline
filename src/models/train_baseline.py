import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from torch.optim.lr_scheduler import ReduceLROnPlateau
import mlflow
import mlflow.data
from mlflow.data.pandas_dataset import PandasDataset
import mlflow.pytorch
from pathlib import Path
from datetime import datetime
import sys
from sklearn.preprocessing import MinMaxScaler

# ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ Í≤ΩÎ°ú Ï∂îÍ∞Ä (Î™®Îìà importÏö©)
PROJECT_DIR = Path(__file__).resolve().parents[2]
sys.path.append(str(PROJECT_DIR))

from src.features.schema import FeatureSchema
from src.models.model_zoo import DeepCNN, CNNAttention, TransformerModel, DLinear, Simple1DCNN
from src.models.model_config import TRAINER_CONFIG, MODEL_CONFIGS # <--- Config Í∞ÄÏ†∏Ïò§Í∏∞

# ==========================================
# 1. Config & Hyperparameters
# ==========================================
def get_model(model_name, input_dim, model_conf):
    """Î™®Îç∏ Ïù¥Î¶ÑÍ≥º ÏÑ§Ï†ïÍ∞íÏùÑ Î∞õÏïÑÏÑú Í∞ùÏ≤¥Î•º ÏÉùÏÑ±Ìï¥Ï£ºÎäî Factory Ìï®Ïàò"""
    if model_name == "DLinear":
        return DLinear(seq_len=model_conf['window_size'], input_dim=input_dim)
    elif model_name == "Transformer":
        return TransformerModel(input_dim=input_dim, d_model=model_conf['d_model'], nhead=model_conf['nhead'])
    elif model_name == "DeepCNN":
        return DeepCNN(input_dim=input_dim, hidden_dim=model_conf['hidden_dim'])
    
# ==========================================
# 3. Data Preparation (Sliding Window)
# ==========================================
def create_dataset(df, window_size, feature_cols):
    X_list, y_list = [], []
    
    # ÏóîÏßÑÎ≥ÑÎ°ú ÏúàÎèÑÏö∞ ÏûêÎ•¥Í∏∞
    for unit_nr, group in df.groupby('unit_nr'):
        data = group[feature_cols].values
        target = group['RUL'].values
        
        # Îç∞Ïù¥ÌÑ∞Í∞Ä ÏúàÎèÑÏö∞Î≥¥Îã§ ÏßßÏúºÎ©¥ Ìå®Ïä§
        if len(data) < window_size: continue
            
        # Sliding Window (ÏÜçÎèÑ ÏµúÏ†ÅÌôî Î≤ÑÏ†Ñ ÏïÑÎãò, Ïù¥Ìï¥Ïö©)
        for i in range(len(data) - window_size):
            X_list.append(data[i : i + window_size])
            y_list.append(target[i + window_size - 1]) # ÏúàÎèÑÏö∞ ÎÅùÏßÄÏ†êÏùò RUL ÏòàÏ∏°
            
    return np.array(X_list), np.array(y_list)

# ==========================================
# 4. Main Training Pipeline
# ==========================================
def train_model(model_name):
    # 1. ÏÑ§Ï†ï Î°úÎìú (Í≥µÌÜµ ÏÑ§Ï†ï + Î™®Îç∏ Ï†ÑÏö© ÏÑ§Ï†ï Ìï©Ï≤¥)
    if model_name not in MODEL_CONFIGS:
        raise ValueError(f"Unknown model: {model_name}")
    
    # ÎîïÏÖîÎÑàÎ¶¨ Î≥ëÌï© (Python 3.9+)
    config = TRAINER_CONFIG | MODEL_CONFIGS[model_name]
    
    # MLflow ÏÑ∏ÌåÖ
    current_time = datetime.now().strftime("%m%d_%H%M")
    run_name = f"{model_name}_{current_time}"
    mlflow.set_experiment("Turbofan_RUL_Prediction")

    with mlflow.start_run(run_name=run_name):
        print(f"üöÄ Start Training: {model_name}")
        print(f"üìú Applied Config: {config}")
        mlflow.log_params(config) # Ìï©Ï≥êÏßÑ ÏÑ§Ï†ï Í∏∞Î°ù

        # ----------------------------------------
        # Îç∞Ïù¥ÌÑ∞ Î°úÎìú & Ï†ÑÏ≤òÎ¶¨ (Ïù¥Ï†ÑÍ≥º ÎèôÏùºÌïòÏßÄÎßå config ÏÇ¨Ïö©)
        # ----------------------------------------
        data_path = PROJECT_DIR / "data/processed/train_FD001_features.parquet"
        df = pd.read_parquet(data_path)
        
        # Scaling
        scaler = MinMaxScaler()
        df[config['features']] = scaler.fit_transform(df[config['features']])
        
        # Windowing (config['window_size'] ÏÇ¨Ïö©)
        # (create_dataset Ìï®ÏàòÎäî Í∏∞Ï°¥Í≥º ÎèôÏùºÌïòÎã§Í≥† Í∞ÄÏ†ï)
        X, y = create_dataset(df, config['window_size'], config['features'])
        
        # DataLoader ÏÉùÏÑ±
        dataset = TensorDataset(torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32).unsqueeze(1))
        dataloader = DataLoader(dataset, batch_size=config['batch_size'], shuffle=True)

        # ----------------------------------------
        # Î™®Îç∏ Ï¥àÍ∏∞Ìôî (Factory Ìï®Ïàò ÏÇ¨Ïö©)
        # ----------------------------------------
        model = get_model(model_name, len(config['features']), MODEL_CONFIGS[model_name])
        
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])
        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)

        # ----------------------------------------
        # ÌïôÏäµ Î£®ÌîÑ
        # ----------------------------------------
        model.train()
        for epoch in range(config['epochs']):
            epoch_loss = 0
            for batch_X, batch_y in dataloader:
                optimizer.zero_grad()
                outputs = model(batch_X)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
            
            avg_loss = epoch_loss / len(dataloader)
            rmse = np.sqrt(avg_loss)
            
            # Scheduler Step
            scheduler.step(avg_loss)
            
            # Logging
            if (epoch+1) % 10 == 0:
                lr = optimizer.param_groups[0]['lr']
                print(f"Epoch {epoch+1}/{config['epochs']} | RMSE: {rmse:.4f} | LR: {lr:.6f}")
                mlflow.log_metric("rmse", rmse, step=epoch)

        # Ï†ÄÏû•
        mlflow.pytorch.log_model(model, "model")
        print("üéâ Training Finished.")


if __name__ == "__main__":
    train_model(model_type="DLinear")