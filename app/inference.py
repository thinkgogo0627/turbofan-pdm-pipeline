import json
import torch
import joblib
import pandas as pd
import numpy as np
from pathlib import Path

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
ARTIFACT_DIR = BASE_DIR / "artifacts"
PROJECT_DIR = BASE_DIR.parent

# ëª¨ë¸ í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€ (PyTorch ëª¨ë¸ ë¡œë“œ ì‹œ í•„ìˆ˜)
import sys
if str(PROJECT_DIR) not in sys.path:
    sys.path.append(str(PROJECT_DIR))

# ì›ë³¸ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„í¬íŠ¸ (ê°€ì¤‘ì¹˜ë¥¼ ë®ì–´ì”Œìš¸ ê»ë°ê¸°)
from src.models.model_zoo import TransformerModel 
from src.models.model_config import MODEL_CONFIGS

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ì „ì—­ ë³€ìˆ˜ (ë©”ëª¨ë¦¬ ìƒì£¼ìš©)
preprocessors = {}
ensemble_models = []
max_window_size = 0

def load_artifacts():
    """
    [MLOps Architecture] Dynamic Model Factory (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ ë™ì‘)

    â–  ê¸°ëŠ¥ ì„¤ëª… (What this does?):
        - ì´ í•¨ìˆ˜ëŠ” í•˜ë“œì½”ë”©ëœ íŒŒë¼ë¯¸í„°(ì˜ˆ: d_model=128)ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        - export_artifacts.pyê°€ í¬ì¥í•´ì¤€ 'ensemble_meta.json' ì„¤ê³„ë„ë¥¼ ì½ì–´ë“¤ì…ë‹ˆë‹¤.
        - JSONì— ì íŒ hyperparamsë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê° ëª¨ë¸ì´ ê³¼ê±°ì— í•™ìŠµë˜ì—ˆë˜ 
          ì •í™•í•œ ê·œê²©(Shape)ì˜ ê»ë°ê¸°ë¥¼ ë©”ëª¨ë¦¬ì— ë™ì ìœ¼ë¡œ ì°ì–´ëƒ…ë‹ˆë‹¤.
        
    â–  ê¸°ëŒ€ íš¨ê³¼ (Impact):
        - í–¥í›„ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ê°€ íŠ¸ëœìŠ¤í¬ë¨¸ ë ˆì´ì–´ë¥¼ 100ì¸µìœ¼ë¡œ ëŠ˜ë¦¬ë“ , 
          ì°¨ì›ì„ 1024ë¡œ ëŠ˜ë¦¬ë“  ì„œë¹™(FastAPI) ì—”ì§€ë‹ˆì–´ëŠ” ì½”ë“œë¥¼ ê±´ë“œë¦´ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
        - ì§€ì†ì  ë°°í¬(CD, Continuous Deployment) íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬ ê¸°ë°˜ì´ ë©ë‹ˆë‹¤.
    """
    global preprocessors, ensemble_models, max_window_size
    
    print("â³ [MLOps] Reading dynamic metadata & Loading artifacts into memory...")
    
    preprocessors['pca_scaler'] = joblib.load(ARTIFACT_DIR / "pca_scaler.pkl")
    preprocessors['pca_model'] = joblib.load(ARTIFACT_DIR / "pca_model.pkl")
    preprocessors['minmax_scaler'] = joblib.load(ARTIFACT_DIR / "minmax_scaler.pkl")
    
    with open(ARTIFACT_DIR / "ensemble_meta.json", "r") as f:
        meta = json.load(f)
        
    for model_info in meta["models"]:
        w_size = model_info["window_size"]
        max_window_size = max(max_window_size, w_size)
        
        weight_path = ARTIFACT_DIR / model_info["filename"]
        
        # 1. ê»ë°ê¸°ë¥¼ ë§Œë“¤ê¸° 'ì „'ì— ê°€ì¤‘ì¹˜ íŒŒì¼(.pth)ì„ ë¨¼ì € ëœ¯ì–´ë´„ (í˜„ë¬¼ í™•ì¸)
        state_dict = torch.load(weight_path, map_location=device, weights_only=True)
        
        # 2. [ì—­ê³µí•™] ê°€ì¤‘ì¹˜ í…ì„œì˜ í˜•íƒœ(Shape)ì—ì„œ ì§„ì§œ ì•„í‚¤í…ì²˜ ê·œê²©ì„ ì•Œì•„ëƒ„
        # - embedding.weightì˜ í¬ê¸°ëŠ” [d_model, input_dim] ì„. ì—¬ê¸°ì„œ d_model í›”ì³ì˜¤ê¸°!
        d_model_inferred = state_dict['embedding.weight'].shape[0]
        
        # - transformer_encoder.layers.X ì¤‘ì— ê°€ì¥ í° ì¸µìˆ˜(X)ë¥¼ ì°¾ì•„ì„œ +1 í•˜ê¸°!
        layer_keys = [int(k.split('.')[2]) for k in state_dict.keys() if 'transformer_encoder.layers.' in k]
        num_layers_inferred = max(layer_keys) + 1 if layer_keys else 2
        
        # - nheadëŠ” ê°€ì¤‘ì¹˜ ëª¨ì–‘ì—ì„œ ì§ì ‘ ë³´ì´ì§€ ì•Šìœ¼ë¯€ë¡œ JSON ê°’ì„ ì“°ë˜, ì—ëŸ¬ ë°©ì§€ìš© ì•ˆì „ì¥ì¹˜ ì¶”ê°€
        nhead_inferred = model_info.get("hyperparams", {}).get("nhead", 4)
        if d_model_inferred % nhead_inferred != 0: 
            nhead_inferred = 4 # nheadëŠ” ë°˜ë“œì‹œ d_modelì˜ ì•½ìˆ˜ì—¬ì•¼ í•¨

        print(f"  ğŸ” [Reverse Engineering] Inferred Spec -> d_model: {d_model_inferred}, layers: {num_layers_inferred}")
        
        # 3. ì•Œì•„ë‚¸ 'ì§„ì§œ' ê·œê²©ìœ¼ë¡œ ë™ì  ê»ë°ê¸° ìƒì„±!
        model = TransformerModel(
            input_dim=9, 
            d_model=d_model_inferred,
            nhead=nhead_inferred,
            num_layers=num_layers_inferred
        ).to(device)
        
        # 4. ì™„ë²½í•˜ê²Œ ë§ì¶°ì§„ ê»ë°ê¸°ì— ê°€ì¤‘ì¹˜ ë®ì–´ì“°ê¸°
        model.load_state_dict(state_dict)
        model.eval() 
        
        ensemble_models.append({"model": model, "window_size": w_size})
        print(f"  âœ… Loaded {model_info['model_type']} (Window: {w_size})")

def preprocess_data(df: pd.DataFrame) -> np.ndarray:
    """Raw ë°ì´í„°ë¥¼ ëª¨ë¸ ì…ë ¥ìš©ìœ¼ë¡œ ë³€í™˜"""
    raw_sensors = ['sensor_2', 'sensor_3', 'sensor_4', 'sensor_7', 'sensor_11', 'sensor_12', 'sensor_15']
    
    # 1. PCA ì ìš©
    scaled_for_pca = preprocessors['pca_scaler'].transform(df[raw_sensors])
    df['pca_1'] = preprocessors['pca_model'].transform(scaled_for_pca)
    
    # ì¶”ë¡  ì‹œì—ëŠ” ì´ì „ ìŠ¤í…ê³¼ì˜ ì°¨ì´ë¡œ Trendë¥¼ êµ¬í•¨ (ê°„ë‹¨í•œ diff ì—°ì‚°)
    df['pca_1_trend'] = df['pca_1'].diff().fillna(0)
    
    # 2. MinMax Scaling
    final_features = raw_sensors + ['pca_1', 'pca_1_trend']
    df[final_features] = preprocessors['minmax_scaler'].transform(df[final_features])
    
    return df[final_features].values

def predict_rul(raw_data_list: list) -> float:
    """Option B: 3ê°œ ëª¨ë¸ ì¼ë°˜ ì¶”ë¡  í›„ í‰ê· """
    df = pd.DataFrame([vars(item) for item in raw_data_list])
    processed_data = preprocess_data(df) # (N_samples, 9)
    
    predictions = []
    
    with torch.no_grad(): # ì—­ì „íŒŒ ê³„ì‚° ë” (ë©”ëª¨ë¦¬ ì ˆì•½ & ì†ë„ í–¥ìƒ)
        for entry in ensemble_models:
            model = entry["model"]
            w_size = entry["window_size"]
            
            # í•´ë‹¹ ëª¨ë¸ì˜ ìœˆë„ìš° ì‚¬ì´ì¦ˆë§Œí¼ ë°ì´í„° ëì—ì„œ ì˜ë¼ëƒ„
            window_data = processed_data[-w_size:]
            
            # (1, Window_size, 9) í˜•íƒœë¡œ Tensor ë³€í™˜
            X_tensor = torch.tensor(window_data, dtype=torch.float32).unsqueeze(0).to(device)
            
            # ì˜ˆì¸¡ (1ë²ˆë§Œ)
            pred = model(X_tensor).cpu().numpy().flatten()[0]
            predictions.append(pred)
            
    # ìµœì¢… í‰ê·  ë°˜í™˜
    return float(np.mean(predictions))